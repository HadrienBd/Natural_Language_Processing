{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nlp_project_bernard_hadrien.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1ZJ3C-zsNTm_0oMcqDlHYaBY-7UcfNAJr",
      "authorship_tag": "ABX9TyM0VBRINxQUyp0eVkK5eSEw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HadrienBd/Natural_Language_Processing/blob/main/nlp_project_bernard_hadrien.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYEJBqqP0wfR"
      },
      "source": [
        "# **Sentiment analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZXke3ChwrSV"
      },
      "source": [
        "## Sommaire\r\n",
        "\r\n",
        "- [Data preparation](#1)\r\n",
        "    - [Importing librairies](#2)\r\n",
        "    - [Importing data](#3)\r\n",
        "    - [Cleaning data](#4)\r\n",
        "    - [Displaying vocabulary](#5)\r\n",
        "- [Model preparation](#6)\r\n",
        "    - [Shuffle dataset](#6)\r\n",
        "    - [Tokenization](#8)\r\n",
        "    - [Word embedding](#9)\r\n",
        "- [Model training](#10)\r\n",
        "    - [Long Short-Term Memory](#10)\r\n",
        "    - [Training](#10)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrFGmt-d2QDE"
      },
      "source": [
        "<a name='1'></a>\r\n",
        "##Data prepatation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia1d2tK1xKXe"
      },
      "source": [
        "<a name='2'></a>\r\n",
        "###First step : Importing librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ8q2HiOvLpC",
        "outputId": "37274321-7bf0-4de9-87c6-d297f7397d45"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import nltk \r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.snowball import EnglishStemmer\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import re"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLfy9051S-gi"
      },
      "source": [
        "<a name='3'></a>\r\n",
        "###Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKZQUfyjylcV",
        "outputId": "defdb39d-4fc1-48a0-ccdd-6f9435813cd2"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swz_LjJ4yv3q"
      },
      "source": [
        "df = pd.read_csv('gdrive/MyDrive/NLP_DATA/training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-1\")\r\n",
        "df.columns = ['sentiment', 'id', 'date', 'query', 'user_id', 'original_tweet']"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ddNFtsXAz5bB",
        "outputId": "87ba00d6-542f-45c2-dc85-b33915f275f8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user_id</th>\n",
              "      <th>original_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                     original_tweet\n",
              "0          0  ...  is upset that he can't update his Facebook by ...\n",
              "1          0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "2          0  ...    my whole body feels itchy and like its on fire \n",
              "3          0  ...  @nationwideclass no, it's not behaving at all....\n",
              "4          0  ...                      @Kwesidei not the whole crew \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HW8-sjIvP7J"
      },
      "source": [
        "#Remove everything execpt tweet content\r\n",
        "df = df.drop(['id', 'date', 'query', 'user_id'], axis=1)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fsGNisYH2PcU",
        "outputId": "780a6a10-903d-48ea-aa88-041f5c6ed237"
      },
      "source": [
        "#We change label in sentiment : 0 -> Negative 4 -> Positive\r\n",
        "label_to_sentiment = {0:\"Negative\", 4:\"Positive\"}\r\n",
        "def label_decoder(label):\r\n",
        "  return label_to_sentiment[label]\r\n",
        "df.sentiment = df.sentiment.apply(lambda x: label_decoder(x))\r\n",
        "df.head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>original_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Negative</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Negative</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Negative</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Negative</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Negative</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                     original_tweet\n",
              "0  Negative  is upset that he can't update his Facebook by ...\n",
              "1  Negative  @Kenichan I dived many times for the ball. Man...\n",
              "2  Negative    my whole body feels itchy and like its on fire \n",
              "3  Negative  @nationwideclass no, it's not behaving at all....\n",
              "4  Negative                      @Kwesidei not the whole crew "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CuhCpbCUu2Y"
      },
      "source": [
        "Dzisplay data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "HkbAdtB22PbN",
        "outputId": "3a19258b-90f9-4155-c1b7-a6c7d906c24d"
      },
      "source": [
        "val_count = df.sentiment.value_counts()\r\n",
        "\r\n",
        "plt.figure(figsize=(8,4))\r\n",
        "plt.bar(val_count.index, val_count.values)\r\n",
        "plt.title(\"Sentiment Data Distribution\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Sentiment Data Distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMycuH4sZHof"
      },
      "source": [
        "<a name='4'></a>\r\n",
        "###Cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXg86hEx2PUH"
      },
      "source": [
        "stop_words = stopwords.words('english')\r\n",
        "\r\n",
        "stemmer = EnglishStemmer()\r\n",
        "\r\n",
        "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYe76gL62PRk"
      },
      "source": [
        "def clean_data(text, stem=False, stop=False):\r\n",
        "  text = re.sub(\"n't\", 'nt', str(text).lower()).strip()\r\n",
        "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\r\n",
        "  tokens = []\r\n",
        "  for token in text.split():\r\n",
        "    if stop:\r\n",
        "      if token not in stop_words:\r\n",
        "        if stem:\r\n",
        "          tokens.append(stemmer.stem(token))\r\n",
        "        else:\r\n",
        "          tokens.append(token)  \r\n",
        "    else:\r\n",
        "      if stem:\r\n",
        "        tokens.append(stemmer.stem(token))\r\n",
        "      else:\r\n",
        "        tokens.append(token)     \r\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk-a-2VZ2PPQ"
      },
      "source": [
        "df['text'] = df.original_tweet.apply(lambda x: clean_data(x))"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouXwBi11GBpf"
      },
      "source": [
        "df['text_stem'] = df.original_tweet.apply(lambda x: clean_data(x, True))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO65sWORsriz"
      },
      "source": [
        "df['text_stop'] = df.original_tweet.apply(lambda x: clean_data(x, False, True))"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzIsGL45GJFs",
        "outputId": "b4ea7e76-ee0a-49df-d545-80649b8b84ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "df['text_stem_stop'] = df.original_tweet.apply(lambda x: clean_data(x, True, True))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-e7348988aee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_stem_stop'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_tweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-111-e7348988aee0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_stem_stop'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_tweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-107-43fa23bb084d>\u001b[0m in \u001b[0;36mclean_data\u001b[0;34m(text, stem, stop)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m           \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/stem/snowball.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0;31m# STEP 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__step2_suffixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tional\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBVB5M-sc4C4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmmkrDfIqf64"
      },
      "source": [
        "<a name='5'></a>\r\n",
        "###Displaying vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRe_orlkdLWu"
      },
      "source": [
        "positive_words = []\r\n",
        "for tweet in df[df.sentiment == 'Positive'].text_stem_stop :\r\n",
        "  for word in tweet.split():\r\n",
        "    positive_words.append(word)\r\n",
        "\r\n",
        "positive_words_freq = dict()\r\n",
        "for w in positive_words:\r\n",
        "    if w not in positive_words_freq.keys():\r\n",
        "      positive_words_freq[w] = 1\r\n",
        "    else:\r\n",
        "      positive_words_freq[w] += 1\r\n",
        "\r\n",
        "positive_words_freq = dict(reversed(sorted(positive_words_freq.items(), key=lambda item: item[1])))\r\n",
        "print({k: positive_words_freq[k] for k in list(positive_words_freq)[:10]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRlsprW8f2-N"
      },
      "source": [
        "negative_words = []\r\n",
        "for tweet in df[df.sentiment == 'Negative'].text_stem_stop :\r\n",
        "  for word in tweet.split():\r\n",
        "    negative_words.append(word)\r\n",
        "\r\n",
        "negative_words_freq = dict()\r\n",
        "for w in negative_words:\r\n",
        "    if w not in negative_words_freq.keys():\r\n",
        "      negative_words_freq[w] = 1\r\n",
        "    else:\r\n",
        "      negative_words_freq[w] += 1\r\n",
        "\r\n",
        "negative_words_freq = dict(reversed(sorted(negative_words_freq.items(), key=lambda item: item[1])))\r\n",
        "print({k: negative_words_freq[k] for k in list(negative_words_freq)[:10]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ClQJyb2Rc4"
      },
      "source": [
        "<a name='6'></a>\r\n",
        "##Model preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWJd5nH31q_Z"
      },
      "source": [
        "<a name='6'></a>\r\n",
        "###Shuffle dataset\r\n",
        "\r\n",
        "We split out dataset into train data (80%) and test data (20%) and shuffle it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JzG-fE03RsW"
      },
      "source": [
        "TRAIN_SIZE = 0.8\r\n",
        "MAX_NB_WORDS = 100000\r\n",
        "MAX_SEQUENCE_LENGTH = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8642Qxq3Rq8"
      },
      "source": [
        "train_data, test_data = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=7)\r\n",
        "print(\"Train Data size:\", len(train_data))\r\n",
        "print(\"Test Data size\", len(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbTJfAkQ3Rnl"
      },
      "source": [
        "train_data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eZpOqjC163s"
      },
      "source": [
        "<a name='8'></a>\r\n",
        "###Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMzzuLVrJuo9"
      },
      "source": [
        "TRAIN_DATA = train_data.text_stem\r\n",
        "TEST_DATA = test_data.text_stem\r\n",
        "MODEL_PATH = 'text_stem'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q7u1rEq3Rk_"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(TRAIN_DATA)\r\n",
        "\r\n",
        "word_index = tokenizer.word_index\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "print(\"Vocabulary Size :\", vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ZzX5PV3RiX"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(TRAIN_DATA), maxlen = MAX_SEQUENCE_LENGTH)\r\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(TEST_DATA), maxlen = MAX_SEQUENCE_LENGTH)\r\n",
        "\r\n",
        "print(\"x_train shape:\", x_train.shape)\r\n",
        "print(\"x_test shape:\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOTNrpKr3Rfy"
      },
      "source": [
        "labels = train_data.sentiment.unique().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd1VFU-b3Rd0"
      },
      "source": [
        "encoder = LabelEncoder()\r\n",
        "encoder.fit(train_data.sentiment.to_list())\r\n",
        "\r\n",
        "y_train = encoder.transform(train_data.sentiment.to_list())\r\n",
        "y_test = encoder.transform(test_data.sentiment.to_list())\r\n",
        "\r\n",
        "y_train = y_train.reshape(-1,1)\r\n",
        "y_test = y_test.reshape(-1,1)\r\n",
        "\r\n",
        "print(\"y_train shape:\", y_train.shape)\r\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJXauhkNwBPm"
      },
      "source": [
        "<a name='9'></a>\r\n",
        "###Word embedding\r\n",
        "We will use GloVe to build our embedding *layer*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnPEO7R13Rar"
      },
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip\r\n",
        "#!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW8WPrqB3RYu"
      },
      "source": [
        "#GLOVE_EMB = '/kaggle/working/glove.6B.300d.txt'\r\n",
        "GLOVE_EMB = '/content/glove.6B.300d.txt'\r\n",
        "EMBEDDING_DIM = 300\r\n",
        "LR = 1e-3\r\n",
        "BATCH_SIZE = 1024\r\n",
        "EPOCHS = 10\r\n",
        "MODEL_PATH = '.../output/kaggle/working/best_model.hdf5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHfOs0kR3RV5"
      },
      "source": [
        "embeddings_index = {}\r\n",
        "\r\n",
        "f = open(GLOVE_EMB)\r\n",
        "for line in f:\r\n",
        "  values = line.split()\r\n",
        "  word = value = values[0]\r\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\r\n",
        "  embeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "\r\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRIaPVc03RTj"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\r\n",
        "for word, i in word_index.items():\r\n",
        "  embedding_vector = embeddings_index.get(word)\r\n",
        "  if embedding_vector is not None:\r\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhXJ3nXC3RQ6"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(vocab_size,\r\n",
        "                                          EMBEDDING_DIM,\r\n",
        "                                          weights=[embedding_matrix],\r\n",
        "                                          input_length=MAX_SEQUENCE_LENGTH,\r\n",
        "                                          trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Mn7fc73Cx8"
      },
      "source": [
        "<a name='10'></a>\r\n",
        "##Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TqO8ZxE21VS"
      },
      "source": [
        "<a name='10'></a>\r\n",
        "###Long Short-Term Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo02zXh_3uhq"
      },
      "source": [
        "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\r\n",
        "from tensorflow.keras.layers import SpatialDropout1D\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEWisqd93ue_"
      },
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\r\n",
        "embedding_sequences = embedding_layer(sequence_input)\r\n",
        "x = SpatialDropout1D(0.2)(embedding_sequences)\r\n",
        "x = Conv1D(64, 5, activation='relu')(x)\r\n",
        "x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\r\n",
        "x = Dense(512, activation='relu')(x)\r\n",
        "x = Dropout(0.5)(x)\r\n",
        "x = Dense(512, activation='relu')(x)\r\n",
        "outputs = Dense(1, activation='sigmoid')(x)\r\n",
        "model = tf.keras.Model(sequence_input, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuOGv7QY3ucZ"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\r\n",
        "\r\n",
        "model.compile(optimizer=Adam(learning_rate=LR), loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1,\r\n",
        "                                     min_lr = 0.01,\r\n",
        "                                     monitor = 'val_loss',\r\n",
        "                                     verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0ye_UzN3ZTP"
      },
      "source": [
        "<a name='11'></a>\r\n",
        "###Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_m6Th5e3uZ4"
      },
      "source": [
        "print(\"Training on GPU...\") if tf.config.list_physical_devices('GPU') else print(\"Training on CPU...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dojPuL7V3uWz"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\r\n",
        "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcQtvvkB3fHK"
      },
      "source": [
        "<a name='12'></a>\r\n",
        "##Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_MLyX833pBQ"
      },
      "source": [
        "<a name='12'></a>\r\n",
        "###Learning Curve of loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-b3mKa3uUW"
      },
      "source": [
        "s, (at, al) = plt.subplots(2,1)\r\n",
        "at.plot(history.history['accuracy'], c= 'b')\r\n",
        "at.plot(history.history['val_accuracy'], c='r')\r\n",
        "at.set_title('model accuracy')\r\n",
        "at.set_ylabel('accuracy')\r\n",
        "at.set_xlabel('epoch')\r\n",
        "at.legend(['LSTM_train', 'LSTM_val'], loc='upper left')\r\n",
        "\r\n",
        "al.plot(history.history['loss'], c='m')\r\n",
        "al.plot(history.history['val_loss'], c='c')\r\n",
        "al.set_title('model loss')\r\n",
        "al.set_ylabel('loss')\r\n",
        "al.set_xlabel('epoch')\r\n",
        "al.legend(['train', 'val'], loc = 'upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADmBCxr235hK"
      },
      "source": [
        "<a name='12'></a>\r\n",
        "###Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAasDd1F3uRe"
      },
      "source": [
        "def decode_sentiment(score):\r\n",
        "    return \"Positive\" if score>0.5 else \"Negative\"\r\n",
        "\r\n",
        "\r\n",
        "scores = model.predict(x_test, verbose=1, batch_size=10000)\r\n",
        "y_pred_1d = [decode_sentiment(score) for score in scores]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAaZOjOk3uO7"
      },
      "source": [
        "import itertools\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\r\n",
        "def plot_confusion_matrix(cm, classes,\r\n",
        "                          title='Confusion matrix',\r\n",
        "                          cmap=plt.cm.Blues):\r\n",
        "    \"\"\"\r\n",
        "    This function prints and plots the confusion matrix.\r\n",
        "    Normalization can be applied by setting `normalize=True`.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title, fontsize=20)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes, fontsize=13)\r\n",
        "    plt.yticks(tick_marks, classes, fontsize=13)\r\n",
        "\r\n",
        "    fmt = '.2f'\r\n",
        "    thresh = cm.max() / 2.\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\r\n",
        "                 horizontalalignment=\"center\",\r\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.ylabel('True label', fontsize=17)\r\n",
        "    plt.xlabel('Predicted label', fontsize=17)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIJ_mgOI3uMR"
      },
      "source": [
        "cnf_matrix = confusion_matrix(test_data.sentiment.to_list(), y_pred_1d)\r\n",
        "plt.figure(figsize=(6,6))\r\n",
        "plot_confusion_matrix(cnf_matrix, classes=test_data.sentiment.unique(), title=\"Confusion matrix\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmze7FCb39yq"
      },
      "source": [
        "<a name='14'></a>\r\n",
        "###Classification scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDza-6fY3uJc"
      },
      "source": [
        "print(classification_report(list(test_data.sentiment), y_pred_1d))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me-BEQIrdBM6"
      },
      "source": [
        "<a name='15'></a>\r\n",
        "###Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O48152xaoJz"
      },
      "source": [
        "model.save('/content/gdrive/MyDrive/NLP_Model/'+MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C6xONnMcfrv"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "loaded_model = keras.models.load_model('/content/gdrive/MyDrive/NLP_Model/'+MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWRfMPP8dKp5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}